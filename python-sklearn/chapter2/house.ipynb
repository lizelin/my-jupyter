{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 房产公司预测区域房价中位线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = \"datasets/housing\"\n",
    "HOUSING_URL = DOWNLOAD_ROOT + HOUSING_PATH + \"/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "# print(HOUSING_URL)\n",
    "# fetch_housing_data(HOUSING_URL, HOUSING_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data(HOUSING_PATH)\n",
    "housing.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字段含义\n",
    "- longitude：经度\n",
    "- latitude：纬度\n",
    "- housing_median_age: 房龄\n",
    "- total_rooms: 房间总数\n",
    "- total_bedrooms: 卧室数目\n",
    "- population: 人口\n",
    "- households: 家庭\n",
    "- median_income: 收入中位数\n",
    "- median_housing_value: 房价中位数\n",
    "- ocean_proximity: 临近？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数值属性的摘要\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建测试集\n",
    "# 该数据集随机，并不完美。最好每次生成的数据集一致（固定）\n",
    "import numpy as np\n",
    "def split_train_test(data, test_radio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_radio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "train_set, test_set = split_train_test(housing, 0.2)\n",
    "print(len(train_set), \" train +\", len(test_set), \" test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def test_set_check(identifier, test_radio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_radio\n",
    "\n",
    "def split_train_test_by_id(data, test_radio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_radio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "housing_with_id = housing.reset_index() # add index clolumn, 使用index列进行索引\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\n",
    "test_set.head()\n",
    "\n",
    "housing_with_id['id'] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]  # 使用自定义的id列进行索引拆分\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")\n",
    "test_set.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42) # 42是常用的种子\n",
    "test_set.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"median_income\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收入分类（收入的中位数大致聚集在2-5万左右）\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]/1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "housing[\"income_cat\"].hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看看所有住房数据 根据 收入类别的比例分布\n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts()/len(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较不同抽样中，收入的比例是否一致\n",
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts()/len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(housing),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "    \"Random\": income_cat_proportions(test_set)\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"]/compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"]/compare_props[\"Overall\"] - 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复数据集\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从数据探索和可视化中获得洞见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将地理数据可视化\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将alpha属性设置为0.1，更好的看到数据分布\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s代表人口数量（圆半径），c代表房价（颜色），jet是预置的色模板\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", s=housing[\"population\"]/100,label=\"population\", figsize=(10,7),\n",
    "c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True, sharex=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 属性间相关系数\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "california_img = mpimg.imread(\"images\" + \"/california.png\")\n",
    "ax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", s=housing[\"population\"]/100,label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=False, alpha=0.4)\n",
    "plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5, cmap=plt.get_cmap(\"jet\"))\n",
    "plt.ylabel(\"Latitude\", fontsize=14)\n",
    "plt.xlabel(\"Longitude\", fontsize=14)\n",
    "\n",
    "prices = housing[\"median_house_value\"]\n",
    "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
    "cbar.set_label(\"Median House Value\", fontsize = 16)\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制各个属性间的相关性\n",
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最有影响的是收入中位数\n",
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 几个计算属性\n",
    "# 每个家庭房间数\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "# 卧室数 对比 房间数\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "# 每个家庭人口\n",
    "housing[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离预测数据和标签\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失数据\n",
    "# 删除空数据\n",
    "# housing.dropna(subset=[\"total_bedrooms\"])\n",
    "# housing.drop(\"total_bedrooms\", axis=1)\n",
    "# 使用中位数填充\n",
    "# median = housing[\"total_bedrooms\"].median()\n",
    "# housing[\"total_bedrooms\"].fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn处理缺失值\n",
    "try:\n",
    "    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
    "except ImportError:\n",
    "    from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.median().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr.loc[sample_incomplete_rows.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理文本和分类属性\n",
    "housing_cat = housing[['ocean_proximity']]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "except ImportError:\n",
    "    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义转换器\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# get the right column indices: safer than hard-coding indices 3, 4, 5, 6\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "    list(housing.columns).index(col)\n",
    "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 另外一种自定义转换器\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def add_extra_features(X, add_bedrooms_per_room=True):\n",
    "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "    if add_bedrooms_per_room:\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "        return np.c_[X, rooms_per_household, population_per_household,\n",
    "                     bedrooms_per_room]\n",
    "    else:\n",
    "        return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = FunctionTransformer(add_extra_features, validate=False,\n",
    "                                 kw_args={\"add_bedrooms_per_room\": False})\n",
    "housing_extra_attribs = attr_adder.fit_transform(housing.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
    "    index=housing.index)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征缩放：如果数值差异太大，则需要进行缩放，否则机器学习的算法表现不佳\n",
    "# 同比例缩放一般两种方式：最小-最大缩放（又叫归一法） 和 标准化\n",
    "# 归一法一般可使用sklearn的MinMaxScaler转换器\n",
    "# 标准化一般用 StandardScaler\n",
    "# 缩放器只能用来拟合训练集，而不是完整的数据集（包括测试集）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转化流水线\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler())])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数值和分类属性\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('label_binarizer', LabelBinarizer())\n",
    "])\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ()\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}